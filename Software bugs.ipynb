{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b2b6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e666b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "885fc30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = '../input/Kannada-MNIST/'\n",
    "# test_dir = 'test.csv'\n",
    "# train_dir = 'train.csv'\n",
    "root_dir = 'D:\\\\filesForNumpyAndPandas\\\\SoftwareDeffects\\\\'\n",
    "test_dir = 'test.csv'\n",
    "train_dir = 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "24424eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(root_dir+train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f00c801b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                   0.001976\n",
      "loc                  0.342642\n",
      "v(g)                 0.301187\n",
      "ev(g)                0.259928\n",
      "iv(g)                0.245618\n",
      "n                    0.258080\n",
      "v                    0.231179\n",
      "l                   -0.253237\n",
      "d                    0.241936\n",
      "i                    0.208577\n",
      "e                    0.095366\n",
      "b                    0.232594\n",
      "t                    0.099592\n",
      "lOCode               0.250604\n",
      "lOComment            0.205402\n",
      "lOBlank              0.257819\n",
      "locCodeAndComment    0.133150\n",
      "uniq_Op              0.178474\n",
      "uniq_Opnd            0.246113\n",
      "total_Op             0.250533\n",
      "total_Opnd           0.252752\n",
      "branchCount          0.322827\n",
      "defects              1.000000\n",
      "Name: defects, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print((data.corr().defects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6b2668e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101763, 19)\n"
     ]
    }
   ],
   "source": [
    "y_train = data['defects'].astype(int)\n",
    "X_train = data.drop(['defects','id','e','t'],axis=1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5edd0db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_0std_1(tensor):\n",
    "    return (tensor - torch.mean(tensor, dim=0)) / torch.std(tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c59d4595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import randint\n",
    "class SMOTE(object):\n",
    "    def __init__(self,distance='euclidian',dims=19,k=5):\n",
    "        super(SMOTE,self).__init__()\n",
    "        self.newindex = 0 \n",
    "        self.k = k\n",
    "        self.dims = dims\n",
    "        self.distance_measure = distance\n",
    "        \n",
    "    def populate(self, N,i,nnarray,min_samples,k):\n",
    "        while N:\n",
    "            nn = randint(0, k-2)\n",
    "            \n",
    "            diff = min_samples[nnarray[nn]] - min_samples[i]\n",
    "            gap = random.uniform(0,1)\n",
    "\n",
    "            self.synthetic_arr[self.newindex,:] = min_samples[i] + gap * diff\n",
    "            \n",
    "            self.newindex += 1\n",
    "            \n",
    "            N -= 1\n",
    "    def k_neighbors(self, euclid_distance, k):\n",
    "        nearest_idx = torch.zeros((euclid_distance.shape[0],euclid_distance.shape[0]), dtype = torch.int64)\n",
    "        #print(euclid_distance.shape)\n",
    "        #return\n",
    "        idxs = torch.argsort(euclid_distance, dim=1)\n",
    "        nearest_idx[:,:] = idxs\n",
    "        \n",
    "        return nearest_idx[:,1:k]\n",
    "    \n",
    "    def find_k(self,X,k):\n",
    "        euclid_distance = torch.zeros((X.shape[0],X.shape[0]), dtype = torch.float32)\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            dif = (X - X[i])**2\n",
    "            dist = torch.sqrt(dif.sum(axis=1))\n",
    "            euclid_distance[i] = dist\n",
    "            \n",
    "        return self.k_neighbors(euclid_distance,k)\n",
    "    \n",
    "    def generate(self, min_samples, N,k):\n",
    "        \"\"\"\n",
    "            Returns (N/100) * n_minority_samples synthetic minority samples.\n",
    "    \t\tParameters\n",
    "    \t\t----------\n",
    "    \t\tmin_samples : Numpy_array-like, shape = [n_minority_samples, n_features]\n",
    "    \t\t    Holds the minority samples\n",
    "    \t\tN : percetange of new synthetic samples: \n",
    "    \t\t    n_synthetic_samples = N/100 * n_minority_samples. Can be < 100.\n",
    "    \t\tk : int. Number of nearest neighbours. \n",
    "    \t\tReturns\n",
    "    \t\t-------\n",
    "    \t\tS : Synthetic samples. array, \n",
    "    \t\t    shape = [(N/100) * n_minority_samples, n_features]. \n",
    "    \t\"\"\"\n",
    "        T = min_samples.shape[0]\n",
    "        self.synthetic_arr = torch.zeros(int(N/100)*T,self.dims)\n",
    "        N = int(N/100)\n",
    "        if self.distance_measure == 'euclidian':\n",
    "            indices = self.find_k(min_samples,k)\n",
    "        for i in range(indices.shape[0]):\n",
    "            self.populate(N, i, indices[i], min_samples, k)\n",
    "        self.newindex = 0 \n",
    "        return self.synthetic_arr\n",
    "            \n",
    "    def fit_generate(self,X,y):\n",
    "        #get occurence of each class\n",
    "        occ = torch.eye(int(y.max()+1),int(y.max()+1))[y].sum(axis=0)\n",
    "\n",
    "        #get the dominant class\n",
    "        dominant_class = torch.argmax(occ)\n",
    "        #get occurence of the dominant class\n",
    "        n_occ = int(occ[dominant_class].item())\n",
    "        for i in range(len(occ)):\n",
    "            if i != dominant_class:\n",
    "                #calculate the amount of synthetic data to generate\n",
    "                N = (n_occ - occ[i]) * 100 / occ[i]\n",
    "                candidates = X[y == i]\n",
    "                xs = self.generate(candidates, N,self.k)\n",
    "                #print(xs.shape)\n",
    "                X = torch.cat((X,xs))\n",
    "                ys = torch.ones(xs.shape[0]) * i\n",
    "                #print(ys.shape)\n",
    "                y = torch.cat((y,ys))\n",
    "        return X,y\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "37b849fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X_train)\n",
    "val_part = 5\n",
    "idx = np.random.permutation(n)\n",
    "X_train = torch.Tensor(X_train.to_numpy())[idx]\n",
    "y_train = torch.Tensor(y_train.to_numpy()).long()[idx]\n",
    "X_train = mean_0std_1(X_train)\n",
    "\n",
    "X_val = X_train[0:int(n/val_part)]\n",
    "y_val = y_train[0:int(n/val_part)]\n",
    "X_train = X_train[int(n/val_part):]\n",
    "y_train = y_train[int(n/val_part):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "45e10567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20352, 19])\n",
      "torch.Size([81411, 19])\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b254bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sm = SMOTE()\n",
    "new_X_train = torch.zeros((0,19))\n",
    "new_y_train = torch.zeros(0)\n",
    "#print(X_train.shape,y_train.shape)\n",
    "batch_size=100\n",
    "for i in range(int(X_train.shape[0] / batch_size)):\n",
    "    X_batch = X_train[i*batch_size:(i+1)*batch_size]\n",
    "    y_batch = y_train[i*batch_size:(i+1)*batch_size]\n",
    "    X,y = sm.fit_generate(X_batch,y_batch)\n",
    "    new_X_train = torch.cat((new_X_train, X))\n",
    "    new_y_train = torch.cat((new_y_train, y))\n",
    "\n",
    "X_train = new_X_train\n",
    "y_train = new_y_train\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8830fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2f88f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20352, 19])\n",
      "torch.Size([118425, 19])\n",
      "tensor(0.2291)\n",
      "tensor(0.4680)\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "print(sum(y_val==1) / len(y_val))\n",
    "print(sum(y_train==1)/ len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06748eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad012c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d7d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9069801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedNetwork(torch.nn.Module):\n",
    "    def __init__(self, hidden_layers_1, hidden_layers_2,hidden_layers_3, hidden_layers_4,\\\n",
    "                 hidden_layers_5,hidden_layers_6,hidden_layers_7,hidden_layers_8):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(19, hidden_layers_1)\n",
    "        self.fc2 = torch.nn.Linear(hidden_layers_1, hidden_layers_2)\n",
    "        self.fc3 = torch.nn.Linear(hidden_layers_2, hidden_layers_3)\n",
    "        self.fc4 = torch.nn.Linear(hidden_layers_3, hidden_layers_4)\n",
    "        self.fc5 = torch.nn.Linear(hidden_layers_4, 1)\n",
    "        self.fc6 = torch.nn.Linear(hidden_layers_5, hidden_layers_6)\n",
    "        self.fc7 = torch.nn.Linear(hidden_layers_6, hidden_layers_7)\n",
    "        self.fc8 = torch.nn.Linear(hidden_layers_7, hidden_layers_8)\n",
    "        self.fc9 = torch.nn.Linear(hidden_layers_8, 1)\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.act1 = torch.nn.LeakyReLU()\n",
    "        \n",
    "        self.act2 = torch.nn.LeakyReLU()\n",
    "        self.act3 =  torch.nn.LeakyReLU()\n",
    "        self.act4 =  torch.nn.LeakyReLU()\n",
    "        self.act5 = torch.nn.Sigmoid()\n",
    "        self.act6 = torch.nn.ReLU()\n",
    "        self.act7 = torch.nn.ReLU()\n",
    "        self.act8 = torch.nn.ReLU()\n",
    "        self.act9 = torch.nn.Sigmoid()\n",
    "        #normaliztion????\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #x = self.dropout(x)\n",
    "       \n",
    "        x = self.fc1(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #x = mean_0std_1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act2(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        #x = mean_0std_1(x)\n",
    "        x = self.fc3(x) \n",
    "        x = self.act3(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "       \n",
    "        #x = mean_0std_1(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = self.act5(x)\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "229ef2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "de1734ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(net, X_train, y_train,X_val,y_val, optimizer, loss_func, epochs, batch_size):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for stage in ['train','val']:\n",
    "            avg_auc = 0\n",
    "            train_acc = 0\n",
    "            loss = 0\n",
    "            n = len(X_train) if stage == 'train' else len(X_val)\n",
    "            idx = np.random.permutation(n)\n",
    "            if stage == 'train':\n",
    "                X_train = X_train[idx]\n",
    "                y_train = y_train[idx]\n",
    "            if stage == 'val':\n",
    "                X_val = X_val[idx]\n",
    "                y_val = y_val[idx]\n",
    "            for batch in range(int(n/batch_size)):\n",
    "                #print(n)\n",
    "                if(stage == 'train'):\n",
    "                    \n",
    "                    X_batch = X_train[batch*batch_size:(batch+1)*batch_size - 1].to(device)\n",
    "                    y_batch = y_train[batch*batch_size:(batch+1)*batch_size - 1].to(device)\n",
    "                else:\n",
    "                    X_batch = X_val[batch*batch_size:(batch+1)*batch_size - 1].to(device)\n",
    "                    y_batch = y_val[batch*batch_size:(batch+1)*batch_size - 1].to(device)\n",
    "\n",
    "                \n",
    "                y_pred = net.forward(X_batch)\n",
    "                #print(y_pred)\n",
    "                with torch.set_grad_enabled(stage == 'train'):\n",
    "                   \n",
    "                    loss_value = loss_func(y_pred.squeeze().float(),y_batch.float())\n",
    "                    \n",
    "                    loss+=loss_value.item()\n",
    "                    \n",
    "                if(stage == 'train'):\n",
    "                    loss_value.backward()\n",
    "                    optimizer.step()\n",
    "                y_pred = y_pred.squeeze()\n",
    "                y_pred[y_pred < 0.5] = 0\n",
    "                y_pred[y_pred > 0.5] = 1\n",
    "                \n",
    "                train_acc += (y_pred==y_batch).float().mean()\n",
    "                #print(y_pred.squeeze())\n",
    "                \n",
    "                avg_auc+= (roc_auc_score(y_batch.cpu().detach().numpy() < 0.5,\\\n",
    "                                    y_pred.squeeze().cpu().detach().numpy() < 0.5))\n",
    "                \n",
    "            \n",
    "            #print(torch.max(net.fc4.weight.grad),torch.min(net.fc4.weight.grad) )\n",
    "            print('epoch: {},stage: {}, accuracy: {}, loss: {}, AUC: {}'.format(epoch,stage,train_acc/int(n/batch_size),\\\n",
    "                                                                              loss/int(n/batch_size),avg_auc/int(n/batch_size)))\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "bc505630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\torch\\nn\\init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "net = FullyConnectedNetwork(128,32,16,8,0,0,0,0).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.0001,weight_decay=0.0001)\n",
    "loss_func = torch.nn.BCELoss()\n",
    "#torch.manual_seed(0)\n",
    "#random.seed(0)\n",
    "epochs = 300\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "affb619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grad(grad):\n",
    "    pass\n",
    "    #print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b5b3d579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0,stage: train, accuracy: 0.6838394999504089, loss: 0.6260727727413178, AUC: 0.6793421945446371\n",
      "epoch: 0,stage: val, accuracy: 0.7334224581718445, loss: 0.5543812908841379, AUC: 0.7197875864781648\n",
      "epoch: 1,stage: train, accuracy: 0.7140340805053711, loss: 0.5923071244922844, AUC: 0.7115978401206574\n",
      "epoch: 1,stage: val, accuracy: 0.7360967397689819, loss: 0.5457684176522981, AUC: 0.7167096698218535\n",
      "epoch: 2,stage: train, accuracy: 0.7177709341049194, loss: 0.5840436463420455, AUC: 0.7133946815460647\n",
      "epoch: 2,stage: val, accuracy: 0.7599661946296692, loss: 0.5883565788748879, AUC: 0.7144726702050787\n",
      "epoch: 3,stage: train, accuracy: 0.7156515717506409, loss: 0.5754902472689345, AUC: 0.7094624044874682\n",
      "epoch: 3,stage: val, accuracy: 0.7823993563652039, loss: 0.5591067283783319, AUC: 0.7026840744815891\n",
      "epoch: 4,stage: train, accuracy: 0.7170050144195557, loss: 0.5735340168347229, AUC: 0.7087312731843793\n",
      "epoch: 4,stage: val, accuracy: 0.7783387303352356, loss: 0.534023384628056, AUC: 0.7178601263360834\n",
      "epoch: 5,stage: train, accuracy: 0.7194992899894714, loss: 0.570299540983664, AUC: 0.7113077519544445\n",
      "epoch: 5,stage: val, accuracy: 0.7817062735557556, loss: 0.5153440000875941, AUC: 0.7151723913753896\n",
      "epoch: 6,stage: train, accuracy: 0.7230067849159241, loss: 0.5648736642824637, AUC: 0.7166862841186202\n",
      "epoch: 6,stage: val, accuracy: 0.7708608508110046, loss: 0.513599564819216, AUC: 0.7081670901081033\n",
      "epoch: 7,stage: train, accuracy: 0.7252289056777954, loss: 0.5630075196317724, AUC: 0.7201458844079668\n",
      "epoch: 7,stage: val, accuracy: 0.766998291015625, loss: 0.5291388087302634, AUC: 0.7118165424790227\n",
      "epoch: 8,stage: train, accuracy: 0.7276972532272339, loss: 0.561394398663495, AUC: 0.7225282177441603\n",
      "epoch: 8,stage: val, accuracy: 0.762046217918396, loss: 0.5398808584648108, AUC: 0.7148142162835933\n",
      "epoch: 9,stage: train, accuracy: 0.7277399897575378, loss: 0.5608226796098658, AUC: 0.7221739684741446\n",
      "epoch: 9,stage: val, accuracy: 0.7740799188613892, loss: 0.5420434581783583, AUC: 0.7124796332074168\n",
      "epoch: 10,stage: train, accuracy: 0.7300382852554321, loss: 0.559457697642816, AUC: 0.7230356940833526\n",
      "epoch: 10,stage: val, accuracy: 0.7695733308792114, loss: 0.549312525012958, AUC: 0.7082476815599518\n",
      "epoch: 11,stage: train, accuracy: 0.7322430610656738, loss: 0.5576794632383295, AUC: 0.7265639143376905\n",
      "epoch: 11,stage: val, accuracy: 0.7662553787231445, loss: 0.5404366425373269, AUC: 0.7141572854698366\n",
      "epoch: 12,stage: train, accuracy: 0.7322940826416016, loss: 0.5544406841252301, AUC: 0.7268450496521272\n",
      "epoch: 12,stage: val, accuracy: 0.7620460391044617, loss: 0.541319007206263, AUC: 0.7068222443127486\n",
      "epoch: 13,stage: train, accuracy: 0.7332392334938049, loss: 0.5539137260333912, AUC: 0.7284540010611389\n",
      "epoch: 13,stage: val, accuracy: 0.766007661819458, loss: 0.5268426263857188, AUC: 0.7126403720241136\n",
      "epoch: 14,stage: train, accuracy: 0.7328394651412964, loss: 0.5537448484188802, AUC: 0.7272147859971756\n",
      "epoch: 14,stage: val, accuracy: 0.7648687958717346, loss: 0.5403868554148284, AUC: 0.708494415366859\n",
      "epoch: 15,stage: train, accuracy: 0.7345502972602844, loss: 0.5519116399417052, AUC: 0.7298431700431163\n",
      "epoch: 15,stage: val, accuracy: 0.7653143405914307, loss: 0.5468237831157708, AUC: 0.7088860685036615\n",
      "epoch: 16,stage: train, accuracy: 0.7372152805328369, loss: 0.5539740525065242, AUC: 0.7320938891931613\n",
      "epoch: 16,stage: val, accuracy: 0.7590252757072449, loss: 0.523491254017788, AUC: 0.7090431082401475\n",
      "epoch: 17,stage: train, accuracy: 0.7358953952789307, loss: 0.5517073145750406, AUC: 0.7320679861199593\n",
      "epoch: 17,stage: val, accuracy: 0.7688798904418945, loss: 0.5231016999895468, AUC: 0.7088227605550192\n",
      "epoch: 18,stage: train, accuracy: 0.7365167140960693, loss: 0.549518336992006, AUC: 0.7308467682809291\n",
      "epoch: 18,stage: val, accuracy: 0.7765557765960693, loss: 0.5162031283168673, AUC: 0.7035400009911814\n",
      "epoch: 19,stage: train, accuracy: 0.7379729747772217, loss: 0.5491169798374176, AUC: 0.732691703189109\n",
      "epoch: 19,stage: val, accuracy: 0.779973030090332, loss: 0.520909643210705, AUC: 0.6997495561587456\n",
      "epoch: 20,stage: train, accuracy: 0.7386874556541443, loss: 0.5500750978572948, AUC: 0.7337101814094767\n",
      "epoch: 20,stage: val, accuracy: 0.7590250372886658, loss: 0.5165413524369774, AUC: 0.7082858183178562\n",
      "epoch: 21,stage: train, accuracy: 0.7377771735191345, loss: 0.5483886018314877, AUC: 0.7335193057349869\n",
      "epoch: 21,stage: val, accuracy: 0.7750699520111084, loss: 0.5458962799243208, AUC: 0.7026496785405846\n",
      "epoch: 22,stage: train, accuracy: 0.7336134314537048, loss: 0.5500300480868365, AUC: 0.7258594909119734\n",
      "epoch: 22,stage: val, accuracy: 0.7666022777557373, loss: 0.5717909047438664, AUC: 0.7086289349535935\n",
      "epoch: 23,stage: train, accuracy: 0.740824818611145, loss: 0.5468469714151847, AUC: 0.7360261831931918\n",
      "epoch: 23,stage: val, accuracy: 0.7604116797447205, loss: 0.5599651216710888, AUC: 0.7092872860711366\n",
      "epoch: 24,stage: train, accuracy: 0.7411567568778992, loss: 0.5466335679711523, AUC: 0.735436164564262\n",
      "epoch: 24,stage: val, accuracy: 0.7722476720809937, loss: 0.5640595665892715, AUC: 0.7053877647790786\n",
      "epoch: 25,stage: train, accuracy: 0.736806333065033, loss: 0.5467973698796452, AUC: 0.7292650159102038\n",
      "epoch: 25,stage: val, accuracy: 0.7758623957633972, loss: 0.5394426033181964, AUC: 0.6950128594775924\n",
      "epoch: 26,stage: train, accuracy: 0.7395387291908264, loss: 0.550299135027705, AUC: 0.7328271411462353\n",
      "epoch: 26,stage: val, accuracy: 0.7747730612754822, loss: 0.5377824610134341, AUC: 0.7070670568842823\n",
      "epoch: 27,stage: train, accuracy: 0.7418800592422485, loss: 0.5509856838148993, AUC: 0.7361231882640548\n",
      "epoch: 27,stage: val, accuracy: 0.7740795612335205, loss: 0.5251377196806781, AUC: 0.704632053849708\n",
      "epoch: 28,stage: train, accuracy: 0.7411993145942688, loss: 0.5534151875006186, AUC: 0.7354346793847395\n",
      "epoch: 28,stage: val, accuracy: 0.7717523574829102, loss: 0.5448907746833825, AUC: 0.6933859302171115\n",
      "epoch: 29,stage: train, accuracy: 0.7396665811538696, loss: 0.55186263783558, AUC: 0.7333014272603945\n",
      "epoch: 29,stage: val, accuracy: 0.7547168135643005, loss: 0.5738212715529796, AUC: 0.7064105928810503\n",
      "epoch: 30,stage: train, accuracy: 0.7426380515098572, loss: 0.5499846393031043, AUC: 0.7376952991989553\n",
      "epoch: 30,stage: val, accuracy: 0.7625906467437744, loss: 0.5563256183885178, AUC: 0.7045413015663373\n",
      "epoch: 31,stage: train, accuracy: 0.7423315048217773, loss: 0.5503159963762438, AUC: 0.736831642534809\n",
      "epoch: 31,stage: val, accuracy: 0.7743768692016602, loss: 0.5304703566263307, AUC: 0.6991296210594202\n",
      "epoch: 32,stage: train, accuracy: 0.7437192797660828, loss: 0.5473372314105163, AUC: 0.7389953958231977\n",
      "epoch: 32,stage: val, accuracy: 0.7724454998970032, loss: 0.5172073166325407, AUC: 0.7001462423370377\n",
      "epoch: 33,stage: train, accuracy: 0.7442127466201782, loss: 0.5468229555117118, AUC: 0.7395422952300322\n",
      "epoch: 33,stage: val, accuracy: 0.7654135227203369, loss: 0.5451422305601947, AUC: 0.7002576417874802\n",
      "epoch: 34,stage: train, accuracy: 0.7405260801315308, loss: 0.5512483705378868, AUC: 0.7338241992203347\n",
      "epoch: 34,stage: val, accuracy: 0.7712569832801819, loss: 0.5834363953872297, AUC: 0.7054827658351605\n",
      "epoch: 35,stage: train, accuracy: 0.7403989434242249, loss: 0.5522981296681069, AUC: 0.7332543287366422\n",
      "epoch: 35,stage: val, accuracy: 0.7733369469642639, loss: 0.5303373441756146, AUC: 0.7004158064300545\n",
      "epoch: 36,stage: train, accuracy: 0.7439238429069519, loss: 0.5504210118989686, AUC: 0.7393956238983804\n",
      "epoch: 36,stage: val, accuracy: 0.7686324715614319, loss: 0.5345158464503739, AUC: 0.7036246584079707\n",
      "epoch: 37,stage: train, accuracy: 0.7427658438682556, loss: 0.5526599451980075, AUC: 0.7367918851298895\n",
      "epoch: 37,stage: val, accuracy: 0.7637794017791748, loss: 0.576891116001321, AUC: 0.6929835948505583\n",
      "epoch: 38,stage: train, accuracy: 0.7393177151679993, loss: 0.5497437577312058, AUC: 0.7319034969688726\n",
      "epoch: 38,stage: val, accuracy: 0.7708608508110046, loss: 0.5689058234481692, AUC: 0.7018960627696911\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train(net, X_train, y_train,X_val,y_val, optimizer, loss_func, epochs, batch_size)\n",
      "Cell \u001b[1;32mIn[148], line 39\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, X_train, y_train, X_val, y_val, optimizer, loss_func, epochs, batch_size)\u001b[0m\n\u001b[0;32m     37\u001b[0m     loss_value\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     38\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 39\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m     40\u001b[0m y_pred[y_pred \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     41\u001b[0m y_pred[y_pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(net, X_train, y_train,X_val,y_val, optimizer, loss_func, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4497409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0a430d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id    loc  v(g)  ev(g)  iv(g)      n        v     l      d      i  \\\n",
      "0      101763   33.0   5.0    1.0    4.0  144.0   824.82  0.04  26.96  30.05   \n",
      "1      101764   27.0   8.0    8.0    2.0  125.0   646.24  0.04  22.82  27.22   \n",
      "2      101765  130.0  11.0    7.0   10.0  545.0  3831.40  0.02  48.15  66.17   \n",
      "3      101766   65.0   7.0    1.0    7.0  156.0   855.71  0.06  17.23  49.89   \n",
      "4      101767   22.0   3.0    1.0    3.0   52.0   238.42  0.10   9.60  26.70   \n",
      "...       ...    ...   ...    ...    ...    ...      ...   ...    ...    ...   \n",
      "67837  169600   41.0   1.0    1.0    1.0  125.0   656.55  0.07  14.00  47.61   \n",
      "67838  169601   20.0   3.0    1.0    3.0   38.0   161.42  0.15   6.75  23.28   \n",
      "67839  169602   24.0   2.0    1.0    2.0   52.0   240.00  0.11   9.00  26.67   \n",
      "67840  169603   18.0   2.0    1.0    1.0   49.0   216.64  0.11   9.33  24.02   \n",
      "67841  169604  101.0  15.0   10.0    5.0    0.0     0.00  0.00   0.00   0.00   \n",
      "\n",
      "       ...        t  lOCode  lOComment  lOBlank  locCodeAndComment  uniq_Op  \\\n",
      "0      ...  1257.60      30          0        3                  0     21.0   \n",
      "1      ...   804.58      23          0        2                  0     18.0   \n",
      "2      ...  6453.34      99          9       17                  1     26.0   \n",
      "3      ...   896.42      45          8       10                  0     15.0   \n",
      "4      ...   145.80      16          0        4                  0     12.0   \n",
      "...    ...      ...     ...        ...      ...                ...      ...   \n",
      "67837  ...   479.35      31          0        7                  0     14.0   \n",
      "67838  ...    58.94      15          0        3                  0      9.0   \n",
      "67839  ...   120.00      18          0        4                  0     16.0   \n",
      "67840  ...   117.68      12          0        2                  0      8.0   \n",
      "67841  ...     0.00       0          0        0                  0      0.0   \n",
      "\n",
      "       uniq_Opnd  total_Op  total_Opnd  branchCount  \n",
      "0           23.0      87.0        57.0          9.0  \n",
      "1           19.0      70.0        49.0         15.0  \n",
      "2           53.0     333.0       244.0         21.0  \n",
      "3           26.0      88.0        60.0         13.0  \n",
      "4           15.0      30.0        24.0          5.0  \n",
      "...          ...       ...         ...          ...  \n",
      "67837       27.0      71.0        54.0          1.0  \n",
      "67838       10.0      23.0        15.0          5.0  \n",
      "67839       16.0      36.0        18.0          3.0  \n",
      "67840       12.0      29.0        22.0          3.0  \n",
      "67841        0.0       0.0         0.0         29.0  \n",
      "\n",
      "[67842 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data_test = pd.read_csv(root_dir+test_dir)\n",
    "print(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5280782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cpu()\n",
    "y_pred = net.forward(mean_0std_1(torch.Tensor(data_test.drop(['e','t'],axis=1).values))[:,1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0d15b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for el in y_pred:\n",
    "    #print(el)\n",
    "    l.append(el.item())\n",
    "\n",
    "df = pd.DataFrame({'id':data_test['id'],'label':l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fac82b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id     label\n",
      "0      101763  0.500863\n",
      "1      101764  0.319206\n",
      "2      101765  0.964017\n",
      "3      101766  0.882941\n",
      "4      101767  0.376878\n",
      "...       ...       ...\n",
      "67837  169600  0.459466\n",
      "67838  169601  0.360111\n",
      "67839  169602  0.382065\n",
      "67840  169603  0.145151\n",
      "67841  169604  0.945185\n",
      "\n",
      "[67842 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e29a1fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(root_dir+'submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d30d2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten = torch.Tensor([[1,-1,1],\n",
    "                   [1,0,0],\n",
    "                   [3,3,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481b2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_n = torch.mean(ten,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33975fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ten_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten = (ten - ten_n) /torch.std(ten, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971459ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c45ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
